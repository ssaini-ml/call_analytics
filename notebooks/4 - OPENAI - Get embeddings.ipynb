{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from src.openai_utility import authenticate_openai_client, get_embeddings\n",
    "from src.settings import PATH_AIRCALL_PROCESSED, PATH_OPENAI_EMBEDDINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - OpenAI - Get embeddings\n",
    "\n",
    "This notebook retrieves text embeddings for call-related text features using OpenAIâ€™s embedding API (e.g., text-embedding-3-large). These embeddings represent the semantic content of text in high-dimensional vector space and are a critical component for downstream machine learning tasks.\n",
    "\n",
    "The input text can be full transcriptions, summaries, or other derived textual representations (e.g., customer-only summaries). This notebook handles batching, API interaction, and storage of the resulting embeddings for further use in the modeling pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Specify the following variables ###\n",
    "INPUT_FILE = \"20250101_20250224_PS_addedfeatures.csv\" # Just edit the filename. Directory is handled below data/aircall/processed\n",
    "\n",
    "## Feature to embed ##\n",
    "# Choose between \"transcription\", \"summary\", and \"topics\" for original Aircall features.\n",
    "# Choose between \"transcription_customer_only\", \"summary_customer_only\", and \"summary_guided\" for the processed Aircall features.\n",
    "FEATURE_TO_EMBED=\"summary_customer_only\"\n",
    "######################\n",
    "\n",
    "EMBEDDING_MODEL=\"text-embedding-3-large\"\n",
    "#######################################\n",
    "\n",
    "os.makedirs(PATH_OPENAI_EMBEDDINGS, exist_ok=True)\n",
    "\n",
    "INPUT_FILE_PATH=f\"{PATH_AIRCALL_PROCESSED}/{INPUT_FILE}\"\n",
    "OUTPUT_FILE_PATH=f\"{PATH_OPENAI_EMBEDDINGS}/{INPUT_FILE.replace('.csv', '')}_{FEATURE_TO_EMBED}_embeddings_{EMBEDDING_MODEL}.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calls_df = pd.read_csv(INPUT_FILE_PATH, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Empty Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not all calls have a transcription, summary, topics, or sentiment. Replacing the PII artifact of that here with NA\n",
    "calls_df.replace(\"Error: Document text is empty.\", pd.NA, inplace=True)\n",
    "\n",
    "calls_df = calls_df[[\"id\", FEATURE_TO_EMBED]]\n",
    "calls_df.dropna(subset=[FEATURE_TO_EMBED], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calls_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = authenticate_openai_client()\n",
    "\n",
    "calls_df[\"embeddings\"], calls_df[\"usage\"] = zip(*calls_df[FEATURE_TO_EMBED].apply(lambda x: get_embeddings(client=client, text=x, model=EMBEDDING_MODEL)))\n",
    "\n",
    "# Example: Assuming df[\"embeddings\"] contains lists of 3072 floats\n",
    "df_embeddings = pd.DataFrame(calls_df[\"embeddings\"].apply(pd.Series))\n",
    "\n",
    "# Rename columns to embedding_0, embedding_1, ..., embedding_3071\n",
    "df_embeddings.columns = [f\"embedding_{i}\" for i in range(df_embeddings.shape[1])]\n",
    "\n",
    "# Concatenate back with original DataFrame (optional)\n",
    "calls_df = pd.concat([calls_df, df_embeddings], axis=1)\n",
    "\n",
    "# Drop the original embeddings column (optional)\n",
    "calls_df.drop(columns=[FEATURE_TO_EMBED, \"embeddings\"], inplace=True)\n",
    "\n",
    "# embeddings, usage = get_embeddings(client=client, text=\"Hello world!\", model=EMBEDDING_MODEL)\n",
    "# print(len(embeddings), usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calls_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calls_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calls_df.usage.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calls_df.to_csv(OUTPUT_FILE_PATH, index=False, encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
