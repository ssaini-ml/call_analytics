{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "from datetime import date, datetime\n",
    "\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "import pytz\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.api_utils import datetime_to_unix, fetch_all_pages, make_request\n",
    "from src.conversation import Conversation\n",
    "from src.pii_utility import authenticate_pii_client, redact_pii_with_batches\n",
    "from src.settings import (\n",
    "    AIRCALL_API_BASE64_CREDENTIALS,\n",
    "    AIRCALL_API_RATELIMIT,\n",
    "    AIRCALL_API_URL,\n",
    "    AIRCALL_NUMBERS_CS,\n",
    "    AIRCALL_NUMBERS_PS,\n",
    "    PATH_AIRCALL_CALLS,\n",
    "    PATH_AIRCALL_DATA,\n",
    "    PATH_AIRCALL_PROCESSED,\n",
    "    RANDOM_STATE,\n",
    ")\n",
    "from src.utils import day_month_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - DATA RETRIEVAL - Aircall\n",
    "\n",
    "This notebook serves as the first step in our data analysis pipeline by retrieving call data from Aircall’s API. The dataset includes information on calls, associated phone numbers, and Conversation Intelligence (CI) features such as transcripts, summaries, key topics, and sentiment analysis. By structuring and storing this data efficiently, we create a solid foundation for further exploration and modeling.\n",
    "\n",
    "#### Objectives\n",
    "\n",
    "- Authenticate and connect to the Aircall API\n",
    "- Download phonenumbers, call metadata, and CI features\n",
    "- Store the retrieved data in a structured format for further analysis\n",
    "\n",
    "#### [Aircall API](https://developer.aircall.io/api-references)\n",
    "- *GET /v1/numbers*: Fetch all Numbers associated to a company and their information\n",
    "- *GET /v1/calls/search*: Search for specific Calls depending on several Query Params like `user_id`, `phone_number` or `tags`. Given a call transferred between `A` and `B` phone numbers, the call will not appear when filtering by `A` but it will for `B`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Input\n",
    "Please specify the business you are interested in here. Options are:\n",
    "- CS: Customer Service\n",
    "  - +32 2 586 3507 → CS SAE DE (M)\n",
    "- PS: Pharma Service\n",
    "  - +31 85 888 1504 → PS PB EAV IVR Kosmetik (M)\n",
    "  - +31 85 888 1469 → PS PB EAV IVR NEM (M)\n",
    "  - +31 85 888 1524 → PS PB EAV IVR OTC & Rest (M)\n",
    "  - +31 85 888 1515 → PS PB EAV IVR RX (M)\n",
    "  - +31 85 888 1579 → PS PB SAE DE IVR Kosmetik (M)\n",
    "  - +31 85 888 1529 → PS PB SAE DE IVR NEM (M)\n",
    "  - +31 85 888 1610 → PS PB SAE DE IVR OTC & Rest (M)\n",
    "  - +31 85 888 1604 → PS PB SAE DE IVR RX (M)\n",
    "- Other: In case you're interested in other phone numbers. *Note: You will have to specify a valid Number in the cell below when you select this option.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Specify details here ###\n",
    "BUSINESS = 'OTHER'\n",
    "CI_FEATURES = [\"sentiments\", \"summary\", \"topics\", \"transcription\"]\n",
    "SAMPLE_SIZE = 2 # Number of calls to download Conversational Intelligence features for\n",
    "\n",
    "START = date(2025, 3, 8)\n",
    "END = date(2025, 3, 9)\n",
    "#############################\n",
    "\n",
    "### Set values based on business ###\n",
    "if BUSINESS == 'CS':\n",
    "    NUMBERS = AIRCALL_NUMBERS_CS\n",
    "elif BUSINESS == 'PS':\n",
    "    NUMBERS = AIRCALL_NUMBERS_PS\n",
    "elif BUSINESS == 'OTHER':\n",
    "    NUMBERS = ['+31 85 888 1579', '+31 85 888 1529']\n",
    "else:\n",
    "    raise ValueError('Invalid business')\n",
    "####################################\n",
    "\n",
    "### Create folder(s) ###\n",
    "os.makedirs(PATH_AIRCALL_CALLS, exist_ok=True)\n",
    "os.makedirs(PATH_AIRCALL_PROCESSED, exist_ok=True)\n",
    "for CI_FEATURE in CI_FEATURES:\n",
    "    os.makedirs(f'{PATH_AIRCALL_DATA}/{CI_FEATURE}', exist_ok=True)\n",
    "########################\n",
    "\n",
    "print(f'Fetching calls for {BUSINESS} from {START} to {END}.\\nThis includes the following Numbers:\\n{NUMBERS}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate list of days and months in the specified range\n",
    "day_months = day_month_list(START, END)\n",
    "\n",
    "# List to store all calls\n",
    "all_calls = []\n",
    "\n",
    "# Per number, fetch all calls for each day in the specified range\n",
    "for NUMBER in NUMBERS:\n",
    "    for day, month in day_months:\n",
    "        calls = fetch_all_pages(\n",
    "            url=f\"{AIRCALL_API_URL}/calls/search\",\n",
    "            headers={\"Authorization\": f\"Basic {AIRCALL_API_BASE64_CREDENTIALS}\"},\n",
    "            params={\n",
    "                \"from\": datetime_to_unix(datetime(2025, month, day, 0, 0, 0, tzinfo=pytz.timezone(\"Europe/Berlin\"))),\n",
    "                \"to\": datetime_to_unix(datetime(2025, month, day, 23, 59, 59, tzinfo=pytz.timezone(\"Europe/Berlin\"))),\n",
    "                \"direction\": \"inbound\",\n",
    "                \"phone_number\": NUMBER,\n",
    "                },\n",
    "            key=\"calls\",\n",
    "            page_param=\"page\",\n",
    "            rate_limit=AIRCALL_API_RATELIMIT,\n",
    "        )\n",
    "\n",
    "        all_calls.extend(calls)\n",
    "\n",
    "    calls_df = pd.DataFrame(all_calls)\n",
    "\n",
    "    print(f\"Retrieved {calls_df.shape[0]} calls for {NUMBER}.\")\n",
    "\n",
    "    # Continue if no calls were found\n",
    "    if calls_df.empty:\n",
    "        continue\n",
    "\n",
    "    # Unpack relevant nested data\n",
    "    calls_df[\"number_id\"] = calls_df[\"number\"].apply(lambda x: x[\"id\"])\n",
    "    calls_df[\"number_digits\"] = calls_df[\"number\"].apply(lambda x: x[\"digits\"])\t\n",
    "    calls_df[\"number_name\"] = calls_df[\"number\"].apply(lambda x: x[\"name\"])\n",
    "    calls_df[\"number_country\"] = calls_df[\"number\"].apply(lambda x: x[\"country\"])\n",
    "\n",
    "    # Filter relevant columns\n",
    "    calls_df = calls_df[[\n",
    "        \"id\",\n",
    "        \"sid\",\n",
    "        \"direction\",\n",
    "        \"status\",\n",
    "        \"missed_call_reason\",\n",
    "        \"started_at\",\n",
    "        \"answered_at\",\n",
    "        \"ended_at\",\n",
    "        \"duration\",\n",
    "        \"recording\",\n",
    "        \"number_id\",\n",
    "        \"number_digits\",\n",
    "        \"number_name\",\n",
    "        \"number_country\",\n",
    "        # \"transferred_by\", # Omitted, since this is not a Number but an Agent\n",
    "        # \"transferred_to\", # Omitted, since this is not a Number but an Agent\n",
    "        \"country_code_a2\",\n",
    "    ]]\n",
    "\n",
    "    # Save to CSV\n",
    "    calls_df.to_csv(f\"{PATH_AIRCALL_CALLS}/{START.strftime('%Y%m%d')}_{END.strftime('%Y%m%d')}_calls_{NUMBER.replace('+', '').replace(' ', '')}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Calls from File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calls_df = pd.DataFrame()\n",
    "\n",
    "for file in os.listdir(PATH_AIRCALL_CALLS):\n",
    "    if file.startswith(\n",
    "        f\"{START.strftime('%Y%m%d')}_{END.strftime('%Y%m%d')}\"\n",
    "    ) and file.endswith(\n",
    "        tuple([f\"{NUMBER.replace('+', '').replace(' ', '')}.csv\" for NUMBER in NUMBERS])\n",
    "    ):\n",
    "        calls_df = pd.concat([calls_df, pd.read_csv(f\"{PATH_AIRCALL_CALLS}/{file}\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick check here how many Calls we retrieved and which Numbers they were registered at. We'll immediately check if they were recorded and whether they were all inbound as specified in the request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calls_df.pivot_table(\n",
    "    values=[\"id\", \"recording\"],\n",
    "    index=[\"number_name\", \"direction\"],\n",
    "    aggfunc={\"id\": \"count\", \"recording\": \"count\"},\n",
    "    observed=False,\n",
    "    margins=True,\n",
    "    margins_name=\"Total\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here that sometimes different numbers show up or counts deviate from the counts in the individual csv files. This has got to do with the way Aircall stores transferred calls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Calls\n",
    "\n",
    "Depending on your selection of numbers and date range, we could end up with a large amount of calls here. We're likely not going to need the Conversation Intelligence (CI) data for all those calls at the same time. So let's make sure we only download it for a limited subset.\n",
    "\n",
    "*Note*: The rate limit for the Aircall API is - at the time of writing - 60 requests/min. We'll need 4 API calls per Call, i.e. one for every CI feature per call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will get rid of all Calls without a recording, since they will not include the CI features we're interested in. We will then sample the remaining calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = calls_df.copy()[calls_df[\"recording\"].notnull()]\n",
    "sample = sample.sample(SAMPLE_SIZE, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the distributions of Calls over the different Number between the full set and the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calls_df.number_name.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.number_name.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Conversation Intelligence data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will download the CI data for every Call. We will temporarily store the raw responses. These will be processed (incl. anonymization) immediately after. Raw responses will then be deleted and only the anonymized data is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in tqdm(sample.id):\n",
    "    # Get all CI features for each call\n",
    "    for endpoint in CI_FEATURES:\n",
    "        response = make_request(\n",
    "            \"GET\",\n",
    "            f\"{AIRCALL_API_URL}/calls/{id}/{endpoint}\",\n",
    "            headers={\"Authorization\": f\"Basic {AIRCALL_API_BASE64_CREDENTIALS}\"},\n",
    "            params=None,\n",
    "            data=None,\n",
    "            json=None,\n",
    "        )\n",
    "\n",
    "        # Temporarily storing the responses in JSON files\n",
    "        with open(f\"{PATH_AIRCALL_DATA}/{endpoint}/{id}.json\", \"w\") as f:\n",
    "            json.dump(response, f)\n",
    "\n",
    "        # Added a sleep to avoid rate limiting\n",
    "        time.sleep(0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process CI data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Conversation object takes a Call id, loads the CI data from JSONs and parses it. Here, we create more humanly readable text representations out of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[\"conversation\"] = sample[\"id\"].apply(lambda id: Conversation(id))\n",
    "sample[\"transcription\"] = sample[\"conversation\"].apply(lambda cv: cv.transcription_str)\n",
    "sample[\"summary\"] = sample[\"conversation\"].apply(lambda cv: cv.summary_str)\n",
    "sample[\"sentiment\"] = sample[\"conversation\"].apply(lambda cv: cv.sentiments_str)\n",
    "sample[\"topics\"] = sample[\"conversation\"].apply(lambda cv: cv.topics_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redact PII\n",
    "Now we redact summaries, topics, and transcriptions. Sentiments will never include PII."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply() # Required for running async functions in Jupyter notebooks\n",
    "\n",
    "client = await authenticate_pii_client()\n",
    "transcriptions_red = await redact_pii_with_batches(client, sample.transcription)\n",
    "\n",
    "client = await authenticate_pii_client()\n",
    "summaries_red = await redact_pii_with_batches(client, sample.summary)\n",
    "\n",
    "client = await authenticate_pii_client()\n",
    "topics_red = await redact_pii_with_batches(client, sample.topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we replace/remove the non-redacted data in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[\"transcription\"] = transcriptions_red\n",
    "sample[\"summary\"] = summaries_red\n",
    "sample[\"topics\"] = topics_red\n",
    "sample.drop(columns=[\"conversation\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's store the DataFrame in csv format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv(\n",
    "    f\"{PATH_AIRCALL_PROCESSED}/{START.strftime('%Y%m%d')}_{END.strftime('%Y%m%d')}_{BUSINESS}.csv\",\n",
    "    index=False,\n",
    "    encoding=\"latin-1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll make sure the raw API responses - which are likely to include PII - are deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for CI_FEATURE in CI_FEATURES:\n",
    "    if os.path.exists(f\"{PATH_AIRCALL_DATA}/{CI_FEATURE}\"):\n",
    "        shutil.rmtree(f\"{PATH_AIRCALL_DATA}/{CI_FEATURE}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
